{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97254110-7f65-4195-bafd-76df08a5b834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: gensim in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: tqdm in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: wrapt in /Users/nandakumarv/github/emotion-detection/venv/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Library/Frameworks/Python.fr\n",
      "[nltk_data]     amework/Versions/3.12/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Library/Frameworks/Pytho\n",
      "[nltk_data]     n.framework/Versions/3.12/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Library/Frameworks/Python.\n",
      "[nltk_data]     framework/Versions/3.12/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Library/Frameworks/Pytho\n",
      "[nltk_data]     n.framework/Versions/3.12/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Install required libraries\n",
    "!pip install pandas numpy scikit-learn nltk gensim tqdm\n",
    "\n",
    "# Cell 2: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea224f05-bb7f-4f1f-9e9d-504a3cb3c07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Load dataset\n",
    "# Place your dataset CSV (with 'text' and 'emotion' columns) in the same directory or provide a path\n",
    "df = pd.read_csv(\"../data/tweet_emotions.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ffc0d88-8228-47f2-aaaf-a0f8ac0e1292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 40000/40000 [00:02<00:00, 15194.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Preprocess text\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text.lower())\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
    "\n",
    "tqdm.pandas()\n",
    "df[\"tokens\"] = df[\"content\"].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38f51993-c664-4ea0-a827-1c244668e394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>[tiffanylue, know, listenin, bad, habit, earli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>[layin, n, bed, headache, ughhhh, waitin, call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>[funeral, ceremony, gloomy, friday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>[want, hang, friend, soon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>[dannycastillo, want, trade, someone, houston,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1753918954</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "      <td>[johnlloydtaylor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "      <td>[happy, mother, day, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "      <td>[happy, mother, day, mommy, woman, man, long, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "      <td>[niariley, wassup, beautiful, follow, peep, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "      <td>[mopedronin, bullet, train, tokyo, gf, visitin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   sentiment  \\\n",
       "0      1956967341       empty   \n",
       "1      1956967666     sadness   \n",
       "2      1956967696     sadness   \n",
       "3      1956967789  enthusiasm   \n",
       "4      1956968416     neutral   \n",
       "...           ...         ...   \n",
       "39995  1753918954     neutral   \n",
       "39996  1753919001        love   \n",
       "39997  1753919005        love   \n",
       "39998  1753919043   happiness   \n",
       "39999  1753919049        love   \n",
       "\n",
       "                                                 content  \\\n",
       "0      @tiffanylue i know  i was listenin to bad habi...   \n",
       "1      Layin n bed with a headache  ughhhh...waitin o...   \n",
       "2                    Funeral ceremony...gloomy friday...   \n",
       "3                   wants to hang out with friends SOON!   \n",
       "4      @dannycastillo We want to trade with someone w...   \n",
       "...                                                  ...   \n",
       "39995                                   @JohnLloydTaylor   \n",
       "39996                     Happy Mothers Day  All my love   \n",
       "39997  Happy Mother's Day to all the mommies out ther...   \n",
       "39998  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...   \n",
       "39999  @mopedronin bullet train from tokyo    the gf ...   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [tiffanylue, know, listenin, bad, habit, earli...  \n",
       "1        [layin, n, bed, headache, ughhhh, waitin, call]  \n",
       "2                    [funeral, ceremony, gloomy, friday]  \n",
       "3                             [want, hang, friend, soon]  \n",
       "4      [dannycastillo, want, trade, someone, houston,...  \n",
       "...                                                  ...  \n",
       "39995                                  [johnlloydtaylor]  \n",
       "39996                         [happy, mother, day, love]  \n",
       "39997  [happy, mother, day, mommy, woman, man, long, ...  \n",
       "39998  [niariley, wassup, beautiful, follow, peep, ne...  \n",
       "39999  [mopedronin, bullet, train, tokyo, gf, visitin...  \n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf93644-d773-4926-a36e-52193d3c1cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading GloVe: 400000it [00:10, 37019.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load GloVe embeddings (300D recommended)\n",
    "def load_glove_embeddings(glove_path):\n",
    "    embeddings = {}\n",
    "    with open(glove_path, 'r', encoding='utf8') as f:\n",
    "        for line in tqdm(f, desc=\"Loading GloVe\"):\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "glove_model = load_glove_embeddings(\"../embeddings/glove.6B.300d.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8eaec3-574c-4822-81a7-bbb8ef5c4709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing: 100%|████████████████████████████████████████████████| 40000/40000 [00:00<00:00, 105009.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Convert text to vector\n",
    "def get_sentence_vector(tokens, model, dim=300):\n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(dim)\n",
    "\n",
    "X = np.array([get_sentence_vector(tokens, glove_model) for tokens in tqdm(df[\"tokens\"], desc=\"Vectorizing\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9444d65-9ab5-438c-ad61-ff5e61ee7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Encode target labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"sentiment\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aadb809c-aef8-47e4-8634-5ec18772bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0cb5290-6855-4f84-8c4d-2296073970f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        19\n",
      "     boredom       0.00      0.00      0.00        31\n",
      "       empty       0.00      0.00      0.00       162\n",
      "  enthusiasm       0.00      0.00      0.00       163\n",
      "         fun       0.06      0.01      0.01       338\n",
      "   happiness       0.30      0.32      0.31      1028\n",
      "        hate       0.38      0.12      0.18       268\n",
      "        love       0.46      0.36      0.40       762\n",
      "     neutral       0.30      0.51      0.37      1740\n",
      "      relief       0.12      0.01      0.02       352\n",
      "     sadness       0.33      0.16      0.21      1046\n",
      "    surprise       0.30      0.03      0.06       425\n",
      "       worry       0.31      0.49      0.38      1666\n",
      "\n",
      "    accuracy                           0.31      8000\n",
      "   macro avg       0.20      0.15      0.15      8000\n",
      "weighted avg       0.29      0.31      0.28      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Train model and evaluate\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f3f51b2-6fd0-4147-aa19-6d232ac436bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Predict emotion of a new sentence\n",
    "def predict_emotion(text):\n",
    "    tokens = preprocess_text(text)\n",
    "    vector = get_sentence_vector(tokens, glove_model)\n",
    "    pred = clf.predict([vector])[0]\n",
    "    return le.inverse_transform([pred])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e2d4c0-e4e2-40bd-bc92-e439152a54ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion: neutral\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "new_text = \"\"\n",
    "predicted_emotion = predict_emotion(new_text)\n",
    "print(f\"Predicted Emotion: {predicted_emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df3f01e0-b892-4223-bba5-f50cf9583ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glove.6B.300d.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(glove_model, \"glove.6B.300d.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58177d1b-109e-4095-9710-1b47f5e7185c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
